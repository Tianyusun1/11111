# File: integrated_inference.py (V8.7: Single-Stream Batch Inference)

import os
import sys
import torch
import argparse
import yaml
import numpy as np
from PIL import Image
from tqdm import tqdm
from transformers import BertTokenizer
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, DDPMScheduler

# === è·¯å¾„é…ç½® ===
# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ PYTHONPATH ä¸­
current_file_path = os.path.abspath(__file__)
project_root = os.path.dirname(current_file_path)
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥é¡¹ç›®å†…éƒ¨ç»„ä»¶
try:
    from models.poem2layout import Poem2LayoutGenerator
    from inference.greedy_decode import greedy_decode_poem_layout
    from stage2_generation.utils.ink_mask import InkWashMaskGenerator
    from data.visualize import draw_layout
except ImportError as e:
    print(f"[Error] æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œï¼Œæˆ–æ­£ç¡®è®¾ç½® PYTHONPATH")
    sys.exit(1)

# =============================================================
# [æ¶æ„åˆ›æ–°] è‡ªé€‚åº”å¤šå°ºåº¦æƒé‡æ¨¡å— (ControlNetScaler)
# =============================================================
class ControlNetScaler(torch.nn.Module):
    def __init__(self, num_scales=13, init_value=1.0):
        super().__init__()
        self.scales = torch.nn.Parameter(torch.full((num_scales,), init_value, dtype=torch.float32))

    def forward(self, down_samples, mid_sample):
        weighted_down = []
        for i, sample in enumerate(down_samples):
            dtype = sample.dtype
            weighted_down.append(sample * self.scales[i].to(dtype))
        
        dtype = mid_sample.dtype
        weighted_mid = mid_sample * self.scales[-1].to(dtype)
        return weighted_down, weighted_mid

# =============================================================
# [æ¶æ„åˆ›æ–°] æ€åŠ¿é”šå®šå¤„ç†å™¨ (GAP Module)
# =============================================================
class PoemInkAttentionProcessor:
    def __init__(self, dynamic_layout, tokenizer, prompt, device, scale=8.0):
        self.layout = dynamic_layout  
        self.tokenizer = tokenizer
        self.prompt = prompt
        self.device = device
        self.scale = scale 
        self.class_to_keyword = {
            2: "å±±", 3: "æ°´", 4: "äºº", 5: "æ ‘", 6: "å±‹", 
            7: "æ¡¥", 8: "èŠ±", 9: "é¸Ÿ", 10: "å…½"
        }

    def __call__(self, attn, hidden_states, encoder_hidden_states=None, attention_mask=None, **kwargs):
        batch_size, sequence_length, _ = hidden_states.shape
        query = attn.to_q(hidden_states)
        encoder_hidden_states = encoder_hidden_states if encoder_hidden_states is not None else hidden_states
        key = attn.to_k(encoder_hidden_states)
        value = attn.to_v(encoder_hidden_states)
        query = attn.head_to_batch_dim(query)
        key = attn.head_to_batch_dim(key)
        value = attn.head_to_batch_dim(value)
        attention_probs = attn.get_attention_scores(query, key, attention_mask)

        # Gestalt Anchoring
        res = int(np.sqrt(sequence_length))
        h, w = res, res
        tokens = self.tokenizer.encode(self.prompt)
        
        for item in self.layout:
            cls_id = int(item[0])
            keyword = self.class_to_keyword.get(cls_id, None)
            if not keyword: continue
            
            cx, cy, bw, bh = item[1], item[2], item[3], item[4]
            if len(item) >= 7:
                bx, by = item[5], item[6]
            else:
                bx, by = 0.0, 0.0
            
            keyword_token_ids = self.tokenizer.encode(keyword, add_special_tokens=False)
            token_indices = [i for i, t in enumerate(tokens) if t in keyword_token_ids]
            if not token_indices: continue

            x_c, y_c = (cx + bx * 0.15) * w, (cy + by * 0.15) * h
            x1, y1 = int(x_c - (bw/2)*w), int(y_c - (bh/2)*h)
            x2, y2 = int(x_c + (bw/2)*w), int(y_c + (bh/2)*h)
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(w, x2), min(h, y2)

            if x2 > x1 and y2 > y1:
                for idx in token_indices:
                    if idx >= attention_probs.shape[-1]: continue
                    mask = torch.zeros((h, w), device=self.device)
                    mask[y1:y2, x1:x2] = self.scale
                    mask_flat = mask.flatten()
                    attention_probs[:, :, idx] += mask_flat * attention_probs[:, :, idx]

        hidden_states = torch.bmm(attention_probs, value)
        hidden_states = attn.batch_to_head_dim(hidden_states)
        hidden_states = attn.to_out[0](hidden_states)
        hidden_states = attn.to_out[1](hidden_states)
        return hidden_states

# =============================================================
# å‚æ•°è§£æ
# =============================================================
def parse_args():
    parser = argparse.ArgumentParser(description="Integrated Batch Inference (V8.7 Single Stream)")
    
    # è·¯å¾„å‚æ•°
    parser.add_argument("--layout_ckpt", type=str, required=True, help="Stage 1 Checkpoint")
    parser.add_argument("--taiyi_model_path", type=str, default="/home/610-sty/huggingface/Taiyi-Stable-Diffusion-1B-Chinese-v0.1")
    
    # Stage 2 è·¯å¾„ (ç›®å½•æˆ–æ–‡ä»¶)
    # å»ºè®®æŒ‡å‘åŒ…å« controlnet_structure, unet_lora, scaler.pth çš„ç›®å½•
    parser.add_argument("--stage2_checkpoint", type=str, required=True, help="Path to Stage 2 output dir")
    
    # è¾“å‡º
    parser.add_argument("--output_base", type=str, default="outputs/batch_inference_v8", help="Output directory")
    
    return parser.parse_args()

# =============================================================
# ä¸»é€»è¾‘
# =============================================================
def main():
    args = parse_args()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸš€ Running Batch Inference on: {device}")
    
    # 1. åŠ è½½ Layout Generator
    # å°è¯•è‡ªåŠ¨è¯»å– config
    config_path = os.path.join(project_root, "configs", "default.yaml")
    if os.path.exists(config_path):
        with open(config_path, "r") as f:
            config = yaml.safe_load(f)
        model_cfg = config.get('model', {})
    else:
        model_cfg = {'hidden_size': 768, 'bb_size': 128}

    print("[Stage 1] Loading Poem2Layout Generator...")
    # [FIX] æ˜¾å¼æŒ‡å‘ text_encoder å­ç›®å½•ä»¥åŠ è½½ BERT
    bert_subpath = os.path.join(args.taiyi_model_path, "text_encoder")
    
    layout_model = Poem2LayoutGenerator(
        bert_path=bert_subpath,  # <--- ä¿®æ”¹å¤„ï¼šæ‹¼æ¥å­ç›®å½•
        num_classes=9,
        hidden_size=model_cfg.get('hidden_size', 768),
        bb_size=model_cfg.get('bb_size', 128),
        decoder_layers=model_cfg.get('decoder_layers', 6),
        decoder_heads=model_cfg.get('decoder_heads', 8),
        latent_dim=model_cfg.get('latent_dim', 64)
    ).to(device).eval()
    
    # åŠ è½½ Layout æƒé‡
    try:
        ckpt = torch.load(args.layout_ckpt, map_location=device)
        state_dict = ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt
        # å»é™¤ module. å‰ç¼€
        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        layout_model.load_state_dict(state_dict, strict=False)
        print("âœ… Layout model loaded.")
    except Exception as e:
        print(f"âš ï¸ Layout model load failed: {e}")
        return

    # 2. åŠ è½½ Single ControlNet & Pipeline
    print("[Stage 2] Loading Single Stream System...")
    
    # è‡ªåŠ¨å¯»æ‰¾ controlnet ç›®å½•
    c_path = os.path.join(args.stage2_checkpoint, "controlnet_structure")
    if not os.path.exists(c_path): c_path = args.stage2_checkpoint
    
    controlnet = ControlNetModel.from_pretrained(c_path, torch_dtype=torch.float16)
    
    pipe = StableDiffusionControlNetPipeline.from_pretrained(
        args.taiyi_model_path, # ä¿æŒæŒ‡å‘æ ¹ç›®å½•ï¼Œç”¨äºåŠ è½½ model_index.json
        controlnet=controlnet, # å•æµ
        torch_dtype=torch.float16,
        safety_checker=None
    ).to(device)
    
    # åŠ è½½ LoRA
    lora_path = os.path.join(args.stage2_checkpoint, "unet_lora")
    if os.path.exists(lora_path):
        pipe.load_lora_weights(lora_path)
        print(f"âœ… LoRA loaded from {lora_path}")
    
    # 3. æ³¨å…¥ Scaler (V8.7 æ ¸å¿ƒ)
    scaler_path = os.path.join(args.stage2_checkpoint, "scaler_final.pth")
    if not os.path.exists(scaler_path): 
        scaler_path = os.path.join(args.stage2_checkpoint, "scaler.pth")
        
    if os.path.exists(scaler_path):
        print(f"âœ… Loading Learnable Scaler from {scaler_path}")
        scaler_module = ControlNetScaler(num_scales=13)
        scaler_module.load_state_dict(torch.load(scaler_path, map_location=device))
        scaler_module.to(device, dtype=torch.float16)
        
        # Monkey Patch
        original_forward = pipe.controlnet.forward
        def patched_forward(*args, **kwargs):
            down, mid = original_forward(*args, **kwargs)
            return scaler_module(down, mid)
        pipe.controlnet.forward = patched_forward
        print("ğŸ”§ Scaler injected.")
        
        # æ‰“å°æƒé‡é¢„è§ˆ
        scales = scaler_module.scales.detach().cpu().numpy()
        print(f"ğŸ“Š Scales: {scales}")
    else:
        print("âš ï¸ Scaler not found, using default identity.")

    # 4. åˆå§‹åŒ–è¾…åŠ©å·¥å…·
    ink_gen = InkWashMaskGenerator(width=512, height=512)
    tokenizer = BertTokenizer.from_pretrained(args.taiyi_model_path, subfolder="tokenizer")

    # === æµ‹è¯•é›† (Batch Inference) ===
    POEMS_BATCH = [
        "æ˜æœˆæ¾é—´ç…§ï¼Œæ¸…æ³‰çŸ³ä¸Šæµã€‚",
        "å¤§æ¼ å­¤çƒŸç›´ï¼Œé•¿æ²³è½æ—¥åœ†ã€‚", 
        "ä¸¤ä¸ªé»„é¹‚é¸£ç¿ æŸ³ï¼Œä¸€è¡Œç™½é¹­ä¸Šé’å¤©ã€‚",
        "å¿½å¦‚ä¸€å¤œæ˜¥é£æ¥ï¼Œåƒæ ‘ä¸‡æ ‘æ¢¨èŠ±å¼€ã€‚",
        "ç™½æ—¥ä¾å±±å°½ï¼Œé»„æ²³å…¥æµ·æµã€‚",
        "æ¯è—¤è€æ ‘æ˜é¸¦ï¼Œå°æ¡¥æµæ°´äººå®¶ã€‚",
        "é‡æ—·å¤©ä½æ ‘ï¼Œæ±Ÿæ¸…æœˆè¿‘äººã€‚",
        "é‡‡èŠä¸œç¯±ä¸‹ï¼Œæ‚ ç„¶è§å—å±±ã€‚"
    ] 

    print(f"\nğŸ¨ Starting Batch Inference for {len(POEMS_BATCH)} poems...")

    for i, poem in enumerate(tqdm(POEMS_BATCH)):
        poem_clean = poem[:10].replace("ï¼Œ", "_").replace("ã€‚", "").strip()
        save_dir = os.path.join(args.output_base, f"{i+1:02d}_{poem_clean}")
        os.makedirs(save_dir, exist_ok=True)

        # Step 1: Layout
        layout_list = greedy_decode_poem_layout(layout_model, tokenizer, poem, device=device)
        if not layout_list: continue
        layout = np.array(layout_list)

        # Step 2: Visualize
        draw_layout(layout, f"Poem: {poem}", os.path.join(save_dir, "01_layout.png"))

        # Step 3: Ink Mask
        mask_img = ink_gen.convert_boxes_to_mask(layout)
        mask_img.save(os.path.join(save_dir, "02_ink_mask.png"))

        # Step 4: Attention Injection
        attn_proc = PoemInkAttentionProcessor(
            dynamic_layout=layout, 
            tokenizer=pipe.tokenizer, 
            prompt=poem, 
            device=device,
            scale=8.0
        )
        pipe.unet.set_attn_processor(attn_proc)

        # Step 5: Generation
        # [ä¿®æ”¹ç‚¹] å»æ‰ "å†™æ„æ°´å¢¨ç”»..." ç­‰åç¼€ï¼Œå®Œå…¨ä½¿ç”¨åŸå§‹è¯—å¥
        prompt = poem 
        neg_prompt = "ä½è´¨é‡ï¼Œæ¨¡ç³Šï¼Œè‰²å½©æ–‘é©³ï¼Œè¾¹æ¡†ï¼Œæ°´å°ï¼Œç°ä»£å»ºç­‘"
        
        generator = torch.Generator(device=device).manual_seed(2024)
        
        final_image = pipe(
            prompt=prompt,
            negative_prompt=neg_prompt,
            image=mask_img, # å•æµè¾“å…¥
            num_inference_steps=35,
            controlnet_conditioning_scale=1.0, # å¼ºåº¦ç”± scaler å†³å®š
            guidance_scale=7.5,
            generator=generator
        ).images[0]
        
        final_image.save(os.path.join(save_dir, "03_final_painting.png"))

    print(f"âœ… All Done. Results saved to {args.output_base}")

if __name__ == "__main__":
    main()